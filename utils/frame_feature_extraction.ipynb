{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\D-Program Files\\Python\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\D-Program Files\\Python\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load pretrained ResNet model\n",
    "resnet = models.resnet50(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (3): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (3): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (4): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (5): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=2048, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the fully connected layer and the pooling layer\n",
    "# Keep layers up to the penultimate layer\n",
    "feature_extractor = nn.Sequential(*list(resnet.children())[:-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# Test the feature extractor\n",
    "input_tensor = torch.randn(1, 3, 224, 224)  # Example input (batch_size=1, 3 channels, 224x224 image)\n",
    "features = feature_extractor(input_tensor)\n",
    "print(\"Feature shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = \"D:/D-Documents/Self-Improvement/Python/Computer Vision/MS-TCN/Multi-Model/data/gtea/frames\"\n",
    "output_folder = \"D:/D-Documents/Self-Improvement/Python/Computer Vision/MS-TCN/Multi-Model/data/gtea/extracted_frame_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\D-Program Files\\Python\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\D-Program Files\\Python\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video folder: S1_Cheese_C1\n",
      "Features saved for video folder: S1_Cheese_C1\n",
      "Processing video folder: S1_CofHoney_C1\n",
      "Features saved for video folder: S1_CofHoney_C1\n",
      "Processing video folder: S1_Hotdog_C1\n",
      "Features saved for video folder: S1_Hotdog_C1\n",
      "Processing video folder: S1_Pealate_C1\n",
      "Features saved for video folder: S1_Pealate_C1\n",
      "Processing video folder: S1_Peanut_C1\n",
      "Features saved for video folder: S1_Peanut_C1\n",
      "Processing video folder: S1_Tea_C1\n",
      "Features saved for video folder: S1_Tea_C1\n",
      "Processing video folder: S2_Cheese_C1\n",
      "Features saved for video folder: S2_Cheese_C1\n",
      "Processing video folder: S2_Coffee_C1\n",
      "Features saved for video folder: S2_Coffee_C1\n",
      "Processing video folder: S2_CofHoney_C1\n",
      "Features saved for video folder: S2_CofHoney_C1\n",
      "Processing video folder: S2_Hotdog_C1\n",
      "Features saved for video folder: S2_Hotdog_C1\n",
      "Processing video folder: S2_Pealate_C1\n",
      "Features saved for video folder: S2_Pealate_C1\n",
      "Processing video folder: S2_Peanut_C1\n",
      "Features saved for video folder: S2_Peanut_C1\n",
      "Processing video folder: S2_Tea_C1\n",
      "Features saved for video folder: S2_Tea_C1\n",
      "Processing video folder: S3_Cheese_C1\n",
      "Features saved for video folder: S3_Cheese_C1\n",
      "Processing video folder: S3_Coffee_C1\n",
      "Features saved for video folder: S3_Coffee_C1\n",
      "Processing video folder: S3_CofHoney_C1\n",
      "Features saved for video folder: S3_CofHoney_C1\n",
      "Processing video folder: S3_Hotdog_C1\n",
      "Features saved for video folder: S3_Hotdog_C1\n",
      "Processing video folder: S3_Pealate_C1\n",
      "Features saved for video folder: S3_Pealate_C1\n",
      "Processing video folder: S3_Peanut_C1\n",
      "Features saved for video folder: S3_Peanut_C1\n",
      "Processing video folder: S3_Tea_C1\n",
      "Features saved for video folder: S3_Tea_C1\n",
      "Processing video folder: S4_Cheese_C1\n",
      "Features saved for video folder: S4_Cheese_C1\n",
      "Processing video folder: S4_Coffee_C1\n",
      "Features saved for video folder: S4_Coffee_C1\n",
      "Processing video folder: S4_CofHoney_C1\n",
      "Features saved for video folder: S4_CofHoney_C1\n",
      "Processing video folder: S4_Hotdog_C1\n",
      "Features saved for video folder: S4_Hotdog_C1\n",
      "Processing video folder: S4_Pealate_C1\n",
      "Features saved for video folder: S4_Pealate_C1\n",
      "Processing video folder: S4_Peanut_C1\n",
      "Features saved for video folder: S4_Peanut_C1\n",
      "Processing video folder: S4_Tea_C1\n",
      "Features saved for video folder: S4_Tea_C1\n",
      "Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create output directory if not exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Load ResNet model for feature extraction\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove the fully connected layer\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Define preprocessing transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Process each video folder\n",
    "for video_folder in os.listdir(input_folder):\n",
    "    video_path = os.path.join(input_folder, video_folder)\n",
    "    if not os.path.isdir(video_path):\n",
    "        continue  # Skip if it's not a folder\n",
    "\n",
    "    # Create a corresponding folder in the output directory\n",
    "    video_output_path = os.path.join(output_folder, video_folder)\n",
    "    os.makedirs(video_output_path, exist_ok=True)\n",
    "\n",
    "    print(f\"Processing video folder: {video_folder}\")\n",
    "\n",
    "    # Process each frame\n",
    "    for frame_file in os.listdir(video_path):\n",
    "        frame_path = os.path.join(video_path, frame_file)\n",
    "\n",
    "        # Check for valid image file\n",
    "        if not (frame_file.endswith(\".png\") or frame_file.endswith(\".jpg\")):\n",
    "            continue\n",
    "\n",
    "        # Load and preprocess frame\n",
    "        image = Image.open(frame_path).convert(\"RGB\")\n",
    "        input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(input_tensor).squeeze().numpy()  # Remove batch and spatial dimensions\n",
    "\n",
    "        # Save features as .npy\n",
    "        feature_file = os.path.splitext(frame_file)[0] + \".npy\"\n",
    "        feature_path = os.path.join(video_output_path, feature_file)\n",
    "        np.save(feature_path, features)\n",
    "\n",
    "    print(f\"Features saved for video folder: {video_folder}\")\n",
    "\n",
    "print(\"Feature extraction completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Caching the list of root modules, please wait!\n",
      "(This will only be done once - type '%rehashx' to reset cache!)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\completerlib.py:149: UserWarning: using rootmodules_cache requires you to install the `pickleshare` library.\n",
      "  ip.db['rootmodules_cache'] = rootmodules_cache\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"gtea\"\n",
    "gt_path = f\"../data/{dataset}/action_labels/\"\n",
    "frames_path = f\"../data/{dataset}/frames/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking S1_Cheese_C1.txt - GT Labels: 943\n",
      "Mismatch for S1_Cheese_C1.txt: GT Labels = 943, Frames = 245\n",
      "\n",
      "Checking S1_Coffee_C1.txt - GT Labels: 1178\n",
      "\n",
      "Warning: Frames not found for S1_Coffee_C1.txt\n",
      "\n",
      "Checking S1_CofHoney_C1.txt - GT Labels: 1235\n",
      "Mismatch for S1_CofHoney_C1.txt: GT Labels = 1235, Frames = 250\n",
      "\n",
      "Checking S1_Hotdog_C1.txt - GT Labels: 718\n",
      "Mismatch for S1_Hotdog_C1.txt: GT Labels = 718, Frames = 250\n",
      "\n",
      "Checking S1_Pealate_C1.txt - GT Labels: 1384\n",
      "Mismatch for S1_Pealate_C1.txt: GT Labels = 1384, Frames = 249\n",
      "\n",
      "Checking S1_Peanut_C1.txt - GT Labels: 1643\n",
      "Mismatch for S1_Peanut_C1.txt: GT Labels = 1643, Frames = 250\n",
      "\n",
      "Checking S1_Tea_C1.txt - GT Labels: 2009\n",
      "Mismatch for S1_Tea_C1.txt: GT Labels = 2009, Frames = 250\n",
      "\n",
      "Checking S2_Cheese_C1.txt - GT Labels: 634\n",
      "Mismatch for S2_Cheese_C1.txt: GT Labels = 634, Frames = 169\n",
      "\n",
      "Checking S2_Coffee_C1.txt - GT Labels: 1814\n",
      "Mismatch for S2_Coffee_C1.txt: GT Labels = 1814, Frames = 212\n",
      "\n",
      "Checking S2_CofHoney_C1.txt - GT Labels: 823\n",
      "Mismatch for S2_CofHoney_C1.txt: GT Labels = 823, Frames = 195\n",
      "\n",
      "Checking S2_Hotdog_C1.txt - GT Labels: 811\n",
      "Mismatch for S2_Hotdog_C1.txt: GT Labels = 811, Frames = 156\n",
      "\n",
      "Checking S2_Pealate_C1.txt - GT Labels: 1181\n",
      "Mismatch for S2_Pealate_C1.txt: GT Labels = 1181, Frames = 250\n",
      "\n",
      "Checking S2_Peanut_C1.txt - GT Labels: 1465\n",
      "Mismatch for S2_Peanut_C1.txt: GT Labels = 1465, Frames = 250\n",
      "\n",
      "Checking S2_Tea_C1.txt - GT Labels: 1412\n",
      "Mismatch for S2_Tea_C1.txt: GT Labels = 1412, Frames = 250\n",
      "\n",
      "Checking S3_Cheese_C1.txt - GT Labels: 913\n",
      "Mismatch for S3_Cheese_C1.txt: GT Labels = 913, Frames = 250\n",
      "\n",
      "Checking S3_Coffee_C1.txt - GT Labels: 1190\n",
      "Mismatch for S3_Coffee_C1.txt: GT Labels = 1190, Frames = 159\n",
      "\n",
      "Checking S3_CofHoney_C1.txt - GT Labels: 892\n",
      "Mismatch for S3_CofHoney_C1.txt: GT Labels = 892, Frames = 250\n",
      "\n",
      "Checking S3_Hotdog_C1.txt - GT Labels: 862\n",
      "Mismatch for S3_Hotdog_C1.txt: GT Labels = 862, Frames = 138\n",
      "\n",
      "Checking S3_Pealate_C1.txt - GT Labels: 1169\n",
      "Mismatch for S3_Pealate_C1.txt: GT Labels = 1169, Frames = 243\n",
      "\n",
      "Checking S3_Peanut_C1.txt - GT Labels: 964\n",
      "Mismatch for S3_Peanut_C1.txt: GT Labels = 964, Frames = 250\n",
      "\n",
      "Checking S3_Tea_C1.txt - GT Labels: 1361\n",
      "Mismatch for S3_Tea_C1.txt: GT Labels = 1361, Frames = 250\n",
      "\n",
      "Checking S4_Cheese_C1.txt - GT Labels: 805\n",
      "Mismatch for S4_Cheese_C1.txt: GT Labels = 805, Frames = 211\n",
      "\n",
      "Checking S4_Coffee_C1.txt - GT Labels: 964\n",
      "Mismatch for S4_Coffee_C1.txt: GT Labels = 964, Frames = 250\n",
      "\n",
      "Checking S4_CofHoney_C1.txt - GT Labels: 871\n",
      "Mismatch for S4_CofHoney_C1.txt: GT Labels = 871, Frames = 250\n",
      "\n",
      "Checking S4_Hotdog_C1.txt - GT Labels: 655\n",
      "Mismatch for S4_Hotdog_C1.txt: GT Labels = 655, Frames = 178\n",
      "\n",
      "Checking S4_Pealate_C1.txt - GT Labels: 1244\n",
      "Mismatch for S4_Pealate_C1.txt: GT Labels = 1244, Frames = 250\n",
      "\n",
      "Checking S4_Peanut_C1.txt - GT Labels: 934\n",
      "Mismatch for S4_Peanut_C1.txt: GT Labels = 934, Frames = 250\n",
      "\n",
      "Checking S4_Tea_C1.txt - GT Labels: 1151\n",
      "Mismatch for S4_Tea_C1.txt: GT Labels = 1151, Frames = 250\n",
      "\n",
      "\n",
      "Check completed!\n"
     ]
    }
   ],
   "source": [
    "for video_name in os.listdir(gt_path):\n",
    "\n",
    "    if not video_name.endswith(\".txt\"):\n",
    "        continue  \n",
    "\n",
    "    # Ground truth label count\n",
    "    with open(os.path.join(gt_path, video_name), 'r') as f:\n",
    "        gt_labels = f.readlines()\n",
    "    \n",
    "    num_gt_labels = len(gt_labels)\n",
    "\n",
    "    # For, testing\n",
    "    print(f\"Checking {video_name} - GT Labels: {num_gt_labels}\")    \n",
    "\n",
    "    # Frame count\n",
    "    video_folder = os.path.join(frames_path, video_name.replace(\".txt\", \"\"))\n",
    "    \n",
    "    if not os.path.exists(video_folder):\n",
    "        print(f\"\\nWarning: Frames not found for {video_name}\\n\")\n",
    "    \n",
    "        continue\n",
    "\n",
    "    num_frames = len([f for f in os.listdir(video_folder) if f.endswith((\".png\", \".jpg\"))])\n",
    "\n",
    "    if num_gt_labels != num_frames:\n",
    "        print(f\"Mismatch for {video_name}: GT Labels = {num_gt_labels}, Frames = {num_frames}\\n\")\n",
    "\n",
    "print(\"\\nCheck completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ../data/gtea/action_labels/S1_Cheese_C1.txt - GT Labels: 943\n",
      "Mismatch for ../data/gtea/action_labels/S1_Cheese_C1.txt: GT Labels = 943, Frames = 250\n",
      "\n",
      "Checking ../data/gtea/action_labels/S2_Cheese_C1.txt - GT Labels: 634\n",
      "Mismatch for ../data/gtea/action_labels/S2_Cheese_C1.txt: GT Labels = 634, Frames = 250\n",
      "\n",
      "Checking ../data/gtea/action_labels/S3_Cheese_C1.txt - GT Labels: 913\n",
      "Mismatch for ../data/gtea/action_labels/S3_Cheese_C1.txt: GT Labels = 913, Frames = 250\n",
      "\n",
      "Checking ../data/gtea/action_labels/S4_Cheese_C1.txt - GT Labels: 805\n",
      "Mismatch for ../data/gtea/action_labels/S4_Cheese_C1.txt: GT Labels = 805, Frames = 250\n",
      "\n",
      "\n",
      "Check completed!\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    video_name = f\"../data/{dataset}/action_labels/S{i}_Cheese_C1.txt\"\n",
    "    frame_path = f\"../data/{dataset}/frames/S{i}_Cheese_C1\"\n",
    "\n",
    "    # Ground truth label count\n",
    "    with open(video_name, 'r') as f:\n",
    "        gt_labels = f.readlines()\n",
    "\n",
    "    num_gt_labels = len(gt_labels)\n",
    "\n",
    "    # For, testing\n",
    "    print(f\"Checking {video_name} - GT Labels: {num_gt_labels}\")    \n",
    "\n",
    "    if not os.path.exists(frame_path):\n",
    "        print(f\"\\nWarning: Frames not found for {video_name}\\n\")\n",
    "\n",
    "        continue\n",
    "\n",
    "    num_frames = len([f for f in os.listdir(video_folder) if f.endswith((\".png\", \".jpg\"))])\n",
    "\n",
    "    if num_gt_labels != num_frames:\n",
    "        print(f\"Mismatch for {video_name}: GT Labels = {num_gt_labels}, Frames = {num_frames}\\n\")\n",
    "\n",
    "print(\"\\nCheck completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"gtea\"\n",
    "extracted_xml_data_path = f\"../data/{dataset}/extracted_xml_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking S1_Cheese_C1.csv - Rows: 9798\n",
      "Number of unique values: 943\n",
      "\n",
      "Checking S1_Coffee_C1.csv - Rows: 10986\n",
      "Number of unique values: 1178\n",
      "\n",
      "Checking S1_CofHoney_C1.csv - Rows: 11646\n",
      "Number of unique values: 1235\n",
      "\n",
      "Checking S1_Hotdog_C1.csv - Rows: 7386\n",
      "Number of unique values: 718\n",
      "\n",
      "Checking S1_Pealate_C1.csv - Rows: 12990\n",
      "Number of unique values: 1384\n",
      "\n",
      "Checking S1_Peanut_C1.csv - Rows: 14448\n",
      "Number of unique values: 1643\n",
      "\n",
      "Checking S1_Tea_C1.csv - Rows: 16248\n",
      "Number of unique values: 2009\n",
      "\n",
      "Checking S2_Cheese_C1.csv - Rows: 6684\n",
      "Number of unique values: 634\n",
      "\n",
      "Checking S2_Coffee_C1.csv - Rows: 17466\n",
      "Number of unique values: 1814\n",
      "\n",
      "Checking S2_CofHoney_C1.csv - Rows: 7884\n",
      "Number of unique values: 823\n",
      "\n",
      "Checking S2_Hotdog_C1.csv - Rows: 8826\n",
      "Number of unique values: 811\n",
      "\n",
      "Checking S2_Pealate_C1.csv - Rows: 12036\n",
      "Number of unique values: 1181\n",
      "\n",
      "Checking S2_Peanut_C1.csv - Rows: 14370\n",
      "Number of unique values: 1465\n",
      "\n",
      "Checking S2_Tea_C1.csv - Rows: 11628\n",
      "Number of unique values: 1412\n",
      "\n",
      "Checking S3_Cheese_C1.csv - Rows: 10140\n",
      "Number of unique values: 913\n",
      "\n",
      "Checking S3_Coffee_C1.csv - Rows: 12456\n",
      "Number of unique values: 1190\n",
      "\n",
      "Checking S3_CofHoney_C1.csv - Rows: 9360\n",
      "Number of unique values: 892\n",
      "\n",
      "Checking S3_Hotdog_C1.csv - Rows: 9930\n",
      "Number of unique values: 862\n",
      "\n",
      "Checking S3_Pealate_C1.csv - Rows: 13236\n",
      "Number of unique values: 1169\n",
      "\n",
      "Checking S3_Peanut_C1.csv - Rows: 10308\n",
      "Number of unique values: 964\n",
      "\n",
      "Checking S3_Tea_C1.csv - Rows: 14370\n",
      "Number of unique values: 1361\n",
      "\n",
      "Checking S4_Cheese_C1.csv - Rows: 8514\n",
      "Number of unique values: 805\n",
      "\n",
      "Checking S4_Coffee_C1.csv - Rows: 9906\n",
      "Number of unique values: 964\n",
      "\n",
      "Checking S4_CofHoney_C1.csv - Rows: 8820\n",
      "Number of unique values: 871\n",
      "\n",
      "Checking S4_Hotdog_C1.csv - Rows: 6720\n",
      "Number of unique values: 655\n",
      "\n",
      "Checking S4_Pealate_C1.csv - Rows: 12654\n",
      "Number of unique values: 1244\n",
      "\n",
      "Checking S4_Peanut_C1.csv - Rows: 9654\n",
      "Number of unique values: 934\n",
      "\n",
      "Checking S4_Tea_C1.csv - Rows: 12048\n",
      "Number of unique values: 1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for extracted_xml_data in os.listdir(extracted_xml_data_path):\n",
    "    xml_data = pd.read_csv(os.path.join(extracted_xml_data_path, extracted_xml_data))\n",
    "\n",
    "    print(f\"Checking {extracted_xml_data} - Rows: {xml_data.shape[0]}\") # For, testing\n",
    "\n",
    "    unique_values = xml_data[xml_data.columns[0]].unique()\n",
    "\n",
    "    print(f\"Number of unique values: {len(unique_values)}\\n\") # For, testing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
