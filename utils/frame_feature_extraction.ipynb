{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Program Files\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:45<00:00, 2.23MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Loading the pretrained ResNet model\n",
    "resnet = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (3): Bottleneck(\n",
       "     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (3): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (4): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (5): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): Bottleneck(\n",
       "     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       "   (2): Bottleneck(\n",
       "     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=2048, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet.children()) # For, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the fully connected layer and the pooling layer\n",
    "# Keeping layers up to the penultimate layer\n",
    "feature_extractor = nn.Sequential(*list(resnet.children())[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: torch.Size([1, 2048, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "# For, testing the feature extractor\n",
    "input_tensor = torch.randn(1, 3, 224, 224)  # Example input (batch_size=1, 3 channels, 224x224 image)\n",
    "features = feature_extractor(input_tensor)\n",
    "print(\"Feature shape:\", features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"gtea\"\n",
    "input_folder = f\"../data/{dataset}/frames/\"\n",
    "output_folder = f\"../data/{dataset}/extracted_frame_features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9260\\538601925.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for video_folder in tqdm_notebook(os.listdir(input_folder)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7c9948f49741568541d399690c4f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video folder: S1_Cheese_C1\n",
      "Features saved for video folder: S1_Cheese_C1\n",
      "\n",
      "Processing video folder: S1_Coffee_C1\n",
      "Features saved for video folder: S1_Coffee_C1\n",
      "\n",
      "Processing video folder: S1_CofHoney_C1\n",
      "Features saved for video folder: S1_CofHoney_C1\n",
      "\n",
      "Processing video folder: S1_Hotdog_C1\n",
      "Features saved for video folder: S1_Hotdog_C1\n",
      "\n",
      "Processing video folder: S1_Pealate_C1\n",
      "Features saved for video folder: S1_Pealate_C1\n",
      "\n",
      "Processing video folder: S1_Peanut_C1\n",
      "Features saved for video folder: S1_Peanut_C1\n",
      "\n",
      "Processing video folder: S1_Tea_C1\n",
      "Features saved for video folder: S1_Tea_C1\n",
      "\n",
      "Processing video folder: S2_CofHoney_C1\n",
      "Features saved for video folder: S2_CofHoney_C1\n",
      "\n",
      "Processing video folder: S2_Hotdog_C1\n",
      "Features saved for video folder: S2_Hotdog_C1\n",
      "\n",
      "Processing video folder: S2_Pealate_C1\n",
      "Features saved for video folder: S2_Pealate_C1\n",
      "\n",
      "Processing video folder: S2_Peanut_C1\n",
      "Features saved for video folder: S2_Peanut_C1\n",
      "\n",
      "Processing video folder: S2_Tea_C1\n",
      "Features saved for video folder: S2_Tea_C1\n",
      "\n",
      "Processing video folder: S3_Coffee_C1\n",
      "Features saved for video folder: S3_Coffee_C1\n",
      "\n",
      "Processing video folder: S3_CofHoney_C1\n",
      "Features saved for video folder: S3_CofHoney_C1\n",
      "\n",
      "Processing video folder: S3_Pealate_C1\n",
      "Features saved for video folder: S3_Pealate_C1\n",
      "\n",
      "Processing video folder: S3_Tea_C1\n",
      "Features saved for video folder: S3_Tea_C1\n",
      "\n",
      "Processing video folder: S4_Cheese_C1\n",
      "Features saved for video folder: S4_Cheese_C1\n",
      "\n",
      "Processing video folder: S4_CofHoney_C1\n",
      "Features saved for video folder: S4_CofHoney_C1\n",
      "\n",
      "Processing video folder: S4_Hotdog_C1\n",
      "Features saved for video folder: S4_Hotdog_C1\n",
      "\n",
      "Processing video folder: S4_Pealate_C1\n",
      "Features saved for video folder: S4_Pealate_C1\n",
      "\n",
      "Processing video folder: S4_Peanut_C1\n",
      "Features saved for video folder: S4_Peanut_C1\n",
      "\n",
      "Processing video folder: S4_Tea_C1\n",
      "Features saved for video folder: S4_Tea_C1\n",
      "\n",
      "Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])  # Remove the fully connected layer\n",
    "feature_extractor.eval()\n",
    "\n",
    "# Defining preprocessing transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Processing each video folder\n",
    "for video_folder in tqdm_notebook(os.listdir(input_folder)):\n",
    "    video_path = os.path.join(input_folder, video_folder)\n",
    "    \n",
    "    if not os.path.isdir(video_path):\n",
    "        continue  # Skip if it's not a folder\n",
    "\n",
    "    # Creating a corresponding folder in the output directory\n",
    "    video_output_path = os.path.join(output_folder, video_folder)\n",
    "    os.makedirs(video_output_path, exist_ok=True)\n",
    "\n",
    "    print(f\"Processing video folder: {video_folder}\")\n",
    "\n",
    "    # Processing each frame\n",
    "    for frame_file in os.listdir(video_path):\n",
    "        frame_path = os.path.join(video_path, frame_file)\n",
    "\n",
    "        if not (frame_file.endswith(\".png\") or frame_file.endswith(\".jpg\")):\n",
    "            continue\n",
    "\n",
    "        image = Image.open(frame_path).convert(\"RGB\")\n",
    "        input_tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Extracting features\n",
    "        with torch.no_grad():\n",
    "            features = feature_extractor(input_tensor).squeeze().numpy()  # Removing batch and spatial dimensions\n",
    "\n",
    "        # Saving features as .npy\n",
    "        feature_file = os.path.splitext(frame_file)[0] + \".npy\"\n",
    "        feature_path = os.path.join(video_output_path, feature_file)\n",
    "        \n",
    "        np.save(feature_path, features)\n",
    "\n",
    "    print(f\"Features saved for video folder: {video_folder}\")\n",
    "    print()\n",
    "\n",
    "print(\"Feature extraction completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For, Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"gtea\"\n",
    "gt_path = f\"../data/{dataset}/action_labels/\"\n",
    "frames_path = f\"../data/{dataset}/frames/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking S1_Cheese_C1.txt - GT Labels: 943\n",
      "Checking S1_Coffee_C1.txt - GT Labels: 1178\n",
      "Checking S1_CofHoney_C1.txt - GT Labels: 1235\n",
      "Checking S1_Hotdog_C1.txt - GT Labels: 718\n",
      "Checking S1_Pealate_C1.txt - GT Labels: 1384\n",
      "Checking S1_Peanut_C1.txt - GT Labels: 1643\n",
      "Checking S1_Tea_C1.txt - GT Labels: 2009\n",
      "Checking S2_Cheese_C1.txt - GT Labels: 634\n",
      "\n",
      "Warning: Frames not found for S2_Cheese_C1.txt\n",
      "\n",
      "Checking S2_Coffee_C1.txt - GT Labels: 1814\n",
      "Mismatch for S2_Coffee_C1.txt: GT Labels = 1814, Frames = 447\n",
      "\n",
      "Checking S2_CofHoney_C1.txt - GT Labels: 823\n",
      "Checking S2_Hotdog_C1.txt - GT Labels: 811\n",
      "Checking S2_Pealate_C1.txt - GT Labels: 1181\n",
      "Checking S2_Peanut_C1.txt - GT Labels: 1465\n",
      "Checking S2_Tea_C1.txt - GT Labels: 1412\n",
      "Checking S3_Cheese_C1.txt - GT Labels: 913\n",
      "\n",
      "Warning: Frames not found for S3_Cheese_C1.txt\n",
      "\n",
      "Checking S3_Coffee_C1.txt - GT Labels: 1190\n",
      "Checking S3_CofHoney_C1.txt - GT Labels: 892\n",
      "Checking S3_Hotdog_C1.txt - GT Labels: 862\n",
      "\n",
      "Warning: Frames not found for S3_Hotdog_C1.txt\n",
      "\n",
      "Checking S3_Pealate_C1.txt - GT Labels: 1169\n",
      "Checking S3_Peanut_C1.txt - GT Labels: 964\n",
      "\n",
      "Warning: Frames not found for S3_Peanut_C1.txt\n",
      "\n",
      "Checking S3_Tea_C1.txt - GT Labels: 1361\n",
      "Checking S4_Cheese_C1.txt - GT Labels: 805\n",
      "Checking S4_Coffee_C1.txt - GT Labels: 964\n",
      "\n",
      "Warning: Frames not found for S4_Coffee_C1.txt\n",
      "\n",
      "Checking S4_CofHoney_C1.txt - GT Labels: 871\n",
      "Checking S4_Hotdog_C1.txt - GT Labels: 655\n",
      "Checking S4_Pealate_C1.txt - GT Labels: 1244\n",
      "Checking S4_Peanut_C1.txt - GT Labels: 934\n",
      "Checking S4_Tea_C1.txt - GT Labels: 1151\n",
      "\n",
      "Check completed!\n"
     ]
    }
   ],
   "source": [
    "for video_name in os.listdir(gt_path):\n",
    "\n",
    "    if not video_name.endswith(\".txt\"):\n",
    "        continue  \n",
    "\n",
    "    # Ground truth label count\n",
    "    with open(os.path.join(gt_path, video_name), 'r') as f:\n",
    "        gt_labels = f.readlines()\n",
    "    \n",
    "    num_gt_labels = len(gt_labels)\n",
    "\n",
    "    # For, testing\n",
    "    print(f\"Checking {video_name} - GT Labels: {num_gt_labels}\")    \n",
    "\n",
    "    # Frame count\n",
    "    video_folder = os.path.join(frames_path, video_name.replace(\".txt\", \"\"))\n",
    "    \n",
    "    if not os.path.exists(video_folder):\n",
    "        print(f\"\\nWarning: Frames not found for {video_name}\\n\")\n",
    "    \n",
    "        continue\n",
    "\n",
    "    num_frames = len([f for f in os.listdir(video_folder) if f.endswith((\".png\", \".jpg\"))])\n",
    "\n",
    "    if num_gt_labels != num_frames:\n",
    "        print(f\"Mismatch for {video_name}: GT Labels = {num_gt_labels}, Frames = {num_frames}\\n\")\n",
    "\n",
    "print(\"\\nCheck completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Manually removed the mismatched and missing labels and frames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
